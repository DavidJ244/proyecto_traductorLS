# GU√çA R√ÅPIDA: IMPLEMENTAR MODELOS EN 5 PASOS

**Tiempo:** 30 minutos para entender todo

---

## PASO 1: Clonar y Setup (5 min)

```bash
# Clonar
git clone https://github.com/DavidJ244/proyecto_traductorLS.git
cd proyecto_traductorLS/backend

# Crear entorno virtual
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows
# source venv/bin/activate   # macOS/Linux

# Instalar dependencias
pip install -r requirements.txt
```

‚úÖ Verifica que corre:
```bash
python app.py
```

Abre: `http://localhost:8000/docs` (Swagger UI)

---

## PASO 2: Entender d√≥nde va tu c√≥digo (5 min)

Abre: `backend/ai_services.py`

Encontrar√°s esto:

```python
# 3 SERVICIOS - AQU√ç VAS A REEMPLAZAR EL C√ìDIGO

1Ô∏è‚É£  PathDetectionServiceImpl     (l√≠nea ~50)   ‚Üê Detectar pose
2Ô∏è‚É£  GlossGeneratorServiceImpl     (l√≠nea ~125)  ‚Üê Generar glosa
3Ô∏è‚É£  TextTranslationServiceImpl    (l√≠nea ~205)  ‚Üê Traducir texto
```

Cada uno tiene un m√©todo `async` que debes completar.

---

## PASO 3: Primer servicio - Path Detection (10 min)

**¬øQU√â HACE?** Lee un video y detecta pose del cuerpo

**ABRE:** `backend/ai_services.py` l√≠nea ~50

**BUSCA ESTO:**
```python
class PathDetectionServiceImpl(PathDetectionService):
    async def detect_pose_from_video(self, video_path: str) -> Dict:
        # REEMPLAZA ESTO ‚Üì
        await asyncio.sleep(2.5)
        return {...datos simulados...}
```

**REEMPLAZA CON TU C√ìDIGO:**
```python
class PathDetectionServiceImpl(PathDetectionService):
    def __init__(self):
        # Cargar tu modelo en __init__
        import mediapipe as mp
        self.pose = mp.solutions.pose.Pose()
    
    async def detect_pose_from_video(self, video_path: str) -> Dict:
        import cv2
        import time
        
        start = time.time()
        cap = cv2.VideoCapture(video_path)
        keypoints = []
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.pose.process(rgb)
            
            if results.pose_landmarks:
                kpts = [[l.x, l.y, l.z] for l in results.pose_landmarks.landmark]
                keypoints.append(kpts)
        
        cap.release()
        
        return {
            "success": True,
            "keypoints": keypoints,
            "confidence": 0.95,
            "frames_processed": len(keypoints),
            "detection_time_ms": int((time.time() - start) * 1000)
        }
```

‚úÖ **Verifica:**
```bash
python app.py
# Abre http://localhost:8000/docs
# Sube un video y prueba
```

---

## PASO 4: Segundo servicio - Gloss Generator (10 min)

**¬øQU√â HACE?** Convierte keypoints a "CASA TECHO GATO..."

**ABRE:** `backend/ai_services.py` l√≠nea ~125

**REEMPLAZA:**
```python
class GlossGeneratorServiceImpl(GlossGeneratorService):
    def __init__(self):
        # Carga tu modelo LSTM/Transformer
        import tensorflow as tf
        self.model = tf.keras.models.load_model('path/to/your/model.h5')
    
    async def generate_gloss(self, keypoints: List[List[float]]) -> Dict:
        import numpy as np
        import time
        
        start = time.time()
        
        # Pasar keypoints por el modelo
        kpts_array = np.array(keypoints)
        predictions = self.model.predict(kpts_array)
        
        # Convertir predicciones a palabras
        gloss_words = ["PALABRA1", "PALABRA2", "PALABRA3"]  # Tus palabras
        gloss = " ".join(gloss_words)
        
        return {
            "success": True,
            "gloss": gloss,
            "confidence": 0.92,
            "processing_time_ms": int((time.time() - start) * 1000)
        }
```

---

## PASO 5: Tercer servicio - Text Translation (10 min)

**¬øQU√â HACE?** Convierte "CASA TECHO" a "La casa"

**ABRE:** `backend/ai_services.py` l√≠nea ~205

**REEMPLAZA:**
```python
class TextTranslationServiceImpl(TextTranslationService):
    def __init__(self):
        # Cargar modelo de traducci√≥n
        from transformers import pipeline
        self.translator = pipeline("text2text-generation", model="t5-base")
    
    async def translate_gloss_to_text(self, gloss: str) -> Dict:
        import time
        
        start = time.time()
        
        # Traducir con tu modelo
        prompt = f"Translate sign language: {gloss}"
        result = self.translator(prompt, max_length=100)
        translation = result[0]['generated_text']
        
        return {
            "success": True,
            "translation": translation,
            "confidence": 0.88,
            "processing_time_ms": int((time.time() - start) * 1000)
        }
```

---

## PRUEBA FINAL (5 min)

```bash
# 1. Aseg√∫rate que el backend corre
python app.py

# 2. En otra terminal, haz una prueba
curl -X POST http://localhost:8000/api/upload-video \
  -F "file=@video.mp4"

# 3. Copia el job_id de la respuesta

# 4. Procesa
curl -X POST http://localhost:8000/api/process-video/JOB_ID

# 5. Consulta estado
curl http://localhost:8000/api/status/JOB_ID

# 6. Obt√©n resultado
curl http://localhost:8000/api/result/JOB_ID
```

‚úÖ **DEBE DEVOLVER:**
```json
{
  "gloss": "TU_GLOSA_AQUI",
  "translation": "Tu traducci√≥n aqu√≠",
  "confidence_gloss": 0.92,
  "confidence_translation": 0.88
}
```

---

## CHECKLIST R√ÅPIDO

- [ ] Clon√© el repo
- [ ] Setup funciona
- [ ] Backend corre sin errores
- [ ] Reemplac√© Path Detection
- [ ] Reemplac√© Gloss Generator
- [ ] Reemplac√© Text Translation
- [ ] Prob√© flujo completo
- [ ] Funciona! ‚úÖ

---

## ERRORES T√çPICOS

**Error:** `ModuleNotFoundError: No module named 'mediapipe'`
- Usa Python 3.11: `python3.11 -m venv venv`

**Error:** `Model file not found`
- Usa rutas absolutas o relativas al backend/

**Error:** `CUDA not available`
- Instala TensorFlow-GPU o usa CPU

**Error:** `Connection refused`
- ¬øEst√° `python app.py` corriendo?

---

## ¬øM√ÅS AYUDA?

Lee estos archivos (est√°n en el repo):
- `backend/HANDOFF.md` - Instrucciones detalladas
- `backend/API_DOCUMENTATION.md` - Endpoints
- `GUIA_COMPA√ëERO_IA.md` - Gu√≠a t√©cnica completa

---

**¬°√âxito!** üöÄ
